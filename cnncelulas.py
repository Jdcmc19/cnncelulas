# -*- coding: utf-8 -*-
"""CNNCelulas.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OxDeRFrjt0mO5LwfUKwBiLOSd0A7DKkl

# Redes Convolucionales

**Conexión con el google colab**

Es necesario que los archivos estén disponibles en el google drive del usuario.
"""

#ver este ejemplo de aca 
#https://medium.com/predict/using-pytorch-for-kaggles-famous-dogs-vs-cats-challenge-part-1-preprocessing-and-training-407017e1a10c

# Load the Drive helper and mount
#from google.colab import drive

# This will prompt for authorization.
#drive.mount('/content/drive')
#!ls "/content/drive/My Drive/Parma/LibroVersionMasReciente/4_Clasificacion/RedesNeuronales/SrcRedesConvolucionales" #cambiar esto por el db de celulas

"""**Importado de  Librerías**
Se importarán las librerías:


1.   Torch: Pytorch, librería para manipulación de matrices, grafos computacionales y redes neuronales
2.   Numpy: Librería para manipulación de matrices
3.   Pandas: Librería para manipular fuentes de datos, usada para escribir achivos .csv
4.  Torchvision para manejo de conjuntos de datos y transformadas en redes de pytorch
"""

device='cuda'


#!pip3 install torch torchvision




import argparse
#Pytorch library import
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import numpy as np;
#import pandas as pandas;
from scipy import ndimage
from torchvision import datasets, transforms, models
import torch.nn.functional as F
from collections import OrderedDict


from PIL import Image
import os

#from __future__ import print_function
from torch.autograd import Variable
from torchvision import transforms
from torch.utils.data.dataset import Dataset  # For custom datasets


#Para corregir error en depuracion usando pycharm, hacer
"""
Look for the Anaconda directory and set the Library\plugins subdir 
(here c:\ProgramData\Anaconda3\Library\plugins) as environment variable 
QT_PLUGIN_PATH
"""
import matplotlib.pyplot as plt


archivoPesos = "/content/drive/My Drive/Colab/celulas_weights1"

"""**Red Convolucional**

Red convolucional basada en DenseNet

TODO: Arreglar naming para que se vea mas profesional (como usar la palabra features y growth rate y esas cosas)
"""

# Sequential o model, la verdad no estoy seguro. Creo que sequential para que tengan el mismo orden

class DenseLayer(nn.Sequential):
    def __init__(self, inputSize, k):
        super(DenseLayer, self).__init__()

        # este tamanno se define en el paper en la seccion de bottleneck
        reductionSize = 4 * k

        self.add_module('norm1', nn.BatchNorm2d(inputSize))
        self.add_module('relu1', nn.ReLU(inplace=True))
        self.add_module('conv1', nn.Conv2d(inputSize, reductionSize, kernel_size=1, stride=1,
                                           bias=False))  # Sin padding, no se habla de padding en esta parte en el paper

        self.add_module('norm2', nn.BatchNorm2d(reductionSize))
        self.add_module('relu2', nn.ReLU(inplace=True))
        self.add_module('conv2', nn.Conv2d(reductionSize, k, kernel_size=3, stride=1, padding=1, bias=False))

    def forward(self, x):
        # Se pasa lo que reciba por los modulos de esta layer y se retorna
        new_features = super(DenseLayer, self).forward(x)

        # Esto es super importantisimo, esto es la base de DenseNet
        # se concatena lo que se recibio con los nuevos features, en la dimension 1
        return torch.cat((x, new_features), 1)


# dejar usar el foward normal (Pasar por todas las capas)
class DenseBlock(nn.Sequential):
    def __init__(self, numLayers, inputSize, k):
        super(DenseBlock, self).__init__()
        for i in range(numLayers):
            layer = DenseLayer(inputSize + i * k, k)
            self.add_module('denseLayer%d' % (i + 1), layer)

    def forward(self, input):
        x = super(DenseBlock, self).forward(input)
        return x


class TransitionLayer(nn.Sequential):
    def __init__(self, inputSize, outputSize):
        super(TransitionLayer, self).__init__()
        self.add_module('norm', nn.BatchNorm2d(inputSize))
        self.add_module('relu', nn.ReLU(inplace=True))
        self.add_module('conv', nn.Conv2d(inputSize, outputSize,
                                          kernel_size=1, stride=1, bias=False))
        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))

    def forward(self, input):
        x = super(TransitionLayer, self).forward(input)
        return x
      

class GlobalAvgPool2d(nn.Module):
    def __init__(self):
        super(GlobalAvgPool2d, self).__init__()
        self.avgPool = nn.AdaptiveAvgPool2d((1, 1))

    def forward(self, input):
        input = self.avgPool(input)
        return input.view(input.size(0), -1)

"""def __init__(self, k=32, firstPadding=3, layers=(6, 12, 32, 32)):
        super(DenseNet, self).__init__()

        # Bias es false para evitar que la convolucion tenga un bias, solo queremos pesos
        # Esto pues queremos que mejore el flujo de la informacion (aunque el gradiente no corra entre capas) (ver paper)
        self.arqui = nn.Sequential(OrderedDict([
            ('conv0', nn.Conv2d(3, 2 * k, kernel_size=7, stride=2, padding=firstPadding, bias=False)),
            ('pool0', nn.MaxPool2d(kernel_size=3, stride=2, padding=firstPadding // 3))
        ]))

        size = 2 * k

        for i, numLayers in enumerate(layers):
            block = DenseBlock(numLayers=numLayers, inputSize=size, k=k)

            self.arqui.add_module('denseBlock%d' % (i + 1), block)

            size = size + numLayers * k

            # Si no es la ultima capa, hay que agregar el transitionLayer
            if i != len(layers) - 1:
                # se divide entre dos porque la compresion que se utiliza es de 0.5, al igual que en el paper
                trans = TransitionLayer(inputSize=size, outputSize=size // 2)
                self.arqui.add_module('transitionLayer%d' % (i + 1), trans)
                size = size // 2

        self.arqui.add_module('globalAvgPool', GlobalAvgPool2d())  # El 1,1 es el tamaño que quiero que tenga la salida
        # self.arqui.add_module('flatten',)
        self.arqui.add_module('linear', nn.Linear(size
                                                  , 2))
        self.arqui.add_module('softmax', nn.Softmax(dim=1))

        # Esto es codigo del profe
        # Freeze parameters so we don't backprop through them
        for param in self.parameters():
            param.requires_grad = True

        # Esta es la inicializacion que tiene un modulo en pytorch
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.Linear):
                nn.init.constant_(m.bias, 0)

    def forward(self, x):

        output = self.arqui(x)
        return output
"""

"""
Clase que hereda del paquete neural net de pytorch

Es una DenseNet-BC con enfoque en DN-169

Estara muy apegado a lo escrito en el paper original y se parecera a la config
usada para ImageNet


Paper original: https://arxiv.org/pdf/1608.06993v3.pdf
Explicacion cool: https://towardsdatascience.com/review-densenet-image-classification-b6631a8ef803

"""
class DenseNet(nn.Module):
    def __init__(self):
        super(DenseNet, self).__init__()
        #se importan las capas de resnet 50, excepto el top model
        #se importan los pesos de imagenet
        res50_model = models.resnet50( pretrained = True)
        self.res50_conv = nn.Sequential(*list(res50_model.children())[:-2])
        #se asegura que todas las capas sean entrenables
        for param in self.res50_conv.parameters():
          param.requires_grad = True
        #la salida del promediado global es 2048 promedios de los 2048 feature maps que genera resnet
        self.capaCompletamenteConectada1 = nn.Linear(2048, 2)
        #2 clases, perro o gato
        
        
        
        self.densenet121 = models.densenet121(pretrained=True)

        # Freeze parameters so we don't backprop through them
        for param in self.densenet121.parameters():
          param.requires_grad = True

        self.densenet121.classifier = nn.Sequential(nn.Linear(1024, 256),
                                       nn.ReLU(),
                                       nn.Dropout(0.2),
                                       nn.Linear(256, 2),
                                       nn.LogSoftmax(dim=1))
        
    def forward(self, x):
      
      output = self.densenet121(x)
      return output
        

    """
    Pasada hacia adelante, sobrecargado de la clase nn neural network
    @param x, muestra a estimar su salida
    """
    def forward2(self, x):
      #Apila las capas
      #Primero aplica las capas de Resnet50
      x =  self.res50_conv(x)        






      #outputs 2048 activation maps of 8x8 
      #https://resources.wolframcloud.com/NeuralNetRepository/resources/ResNet-50-Trained-on-ImageNet-Competition-Data
      #Promediado de los feature maps
      x =  F.avg_pool2d(x, x.size()[2:])
      #Aplanado
      x = x.view(-1, 2048)
      #Se pasa por la capa completamente conectada
      x = F.relu(self.capaCompletamenteConectada1(x))
      #Dropout para la regularizacion del modelo
      x = F.dropout(x, training = self.training)
      #Salida usando funcion softmax
      output = F.log_softmax(x, dim = 1)        
      return output

from torchsummary import summary
model = DenseNet().to(device)
summary(model, input_size=(3, 224, 224))

"""**Cargador de datos**

Se sobrecarga el cargador de datos, para crear el manipulador de datos a usar en el entrenamiento
"""

"""
Clase que permite cargar datos
"""

class DataSetCelulas(Dataset):
    def __init__(self, samplesDirectory, transform = None):
        """
        Inits the dataset
        :param samplesDirectory: path to the directory with the samples
        :param transform: Pytorch transforms list
        """
        self.transform = transform
        (sampleIds, labels2) = self.fillSampleIdsAndLabels(samplesDirectory)
        self.labels2 = labels2
        self.sampleIds = sampleIds


    def __getitem__(self, index):
        """
        :param index: dataset sample index
        :return: (sample, label)
        """
        samplePath = self.sampleIds[index]
        # Open the image
        imagePIL = Image.open(samplePath)
        imagePIL.mode = "I"
        print("aaaa",imagePIL.mode,"aaa",samplePath)

        #apply transformations

        if self.transform is not None:
            img_as_tensor2 = self.transform(imagePIL)
        #read the label
        y = self.labels2[index]
        #transform label to numpy array
        #y = np.array([y]);
        return (img_as_tensor2, y)

    def __len__(self):
        """
        Returns the length of the dataset
        :return: number of samples
        """
        numSamples = len(self.sampleIds)
        return numSamples


    def fillSampleIdsAndLabels(self, samplesDirectory):
        """
        Extracts sample and label metadata
        :param samplesDirectory: directory of samples
        :return: (file names, label array)
        """
        files = []
        labels = []
        # r=root, d=directories, f = files
        contador = 0
        for r, d, f in os.walk(samplesDirectory):
            for file in f:
                if '.tif' in file:
                    samplePath = os.path.join(r, file)
                    files.append(samplePath)
                    contador +=1
                    if('black' not in samplePath):
                        labels += [0.0]
                    else:
                        labels += [1.0]

        return (files, labels)

"""**Creador del modelo**

Crea el modelo, la funcion de perdida y el optimizador
"""

"""
Create model, loss function and optimizer
@return 
"""
def createModel(learningRate, device):  
  #model = models.densenet121(pretrained=True) 
  #RESNET50 model layers
  
  
  #model = models.densenet121(pretrained=True)

  # Freeze parameters so we don't backprop through them
  #for param in model.parameters():
  #  param.requires_grad = True

  #model.classifier = nn.Sequential(nn.Linear(1024, 256),
  #                               nn.ReLU(),
  #                               nn.Dropout(0.2),
  #                               nn.Linear(256, 2),
  #                              nn.LogSoftmax(dim=1))

  
  #model.to(device)
  
  model = DenseNet().to(device)
  
  
  #funcion de perdida
  criterion = nn.NLLLoss()
  # Debe entrenar todos los parametros
  optimizer = optim.Adam(model.parameters(), lr = learningRate)  
  return (model, optimizer, criterion)

"""entrenador de red"""

"""
Entrena el modelo
@param device, dispositivo en el que se correra el modelo
@dataset, cargador de datos
@epochs, numero de epochs por el que correra el modelo
@learningRate, coeficiente de aprendizaje
@batchSize, tamanio del lote de datos para entrenamiento
"""

def trainModel(device, dataset, epochs, learningRate, batchSize):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    #create the model with the optimizer and the loss function
    (model, optimizer, criterion) = createModel(learningRate, device)
    datasetLoader = torch.utils.data.DataLoader(dataset = dataset, batch_size = batchSize, shuffle = True)
    
    for epoch in range(0, epochs):
      for idLote, (images, labels) in enumerate(datasetLoader):
          images = Variable(images)
          labels = Variable(labels)
          labels = labels.long()
          #save labels and samples to the device
          inputs, labels = images.to(device), labels.to(device)
          
          #put weights to zero
          optimizer.zero_grad()

          #estimated output by the model
          estimatedOutput = model.forward(inputs)

          #calculate model loss
          loss = criterion(estimatedOutput, labels)
          #back propagate error
          loss.backward()
          #update weigths          
          optimizer.step()
          
          #train mode
          model.train()
          
          if idLote % 100 == 0:
            print('Epoch de entrenamiento: {} [{}/{} ({:.0f}%)]\tPerdida: {:.6f}'.format(
                epochs, idLote * len(images), len(datasetLoader.dataset),
                           100. * idLote / len(datasetLoader), loss.item()))
            #guarda el modelo
            torch.save(model.state_dict(), archivoPesos)

        
          
    
def main():
  # Uso de GPU es recomendado
  device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

  print("Using device: ")
  print(device)
  
  trainTransforms = transforms.Compose([transforms.RandomRotation(30),
                                       transforms.RandomResizedCrop(224),
                                       transforms.RandomHorizontalFlip(),
                                       transforms.ToTensor(),
                                       transforms.Normalize([0.485, 0.456, 0.406],
                                                            [0.229, 0.224, 0.225])])
  dataset = DataSetCelulas(".\\dataset", trainTransforms)
  epochs = 100;
  learningRate = 0.001;
  batchSize = 12
  trainModel(device, dataset, epochs, learningRate, batchSize)  
  


if __name__ == '__main__':
    main()

"""Authors: *Saul Calderon"""